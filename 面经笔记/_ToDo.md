<!-- TOC -->

- [网络](#网络)
    - [阐述TCP连接四次挥手](#阐述tcp连接四次挥手)
        - [TCP包头的格式](#tcp包头的格式)
- [操作系统](#操作系统)
    - [进程间通讯](#进程间通讯)
    - [进程和线程的区别](#进程和线程的区别)
    - [如何查看一个进程打开了哪些文件？](#如何查看一个进程打开了哪些文件)
    - [shell](#shell)
    - [tcp慢启动算法](#tcp慢启动算法)
    - [Mysql 比较熟悉是吧？说一下底层数据存储原理？](#mysql-比较熟悉是吧说一下底层数据存储原理)
    - [Python内置字典如何实现对value排序？](#python内置字典如何实现对value排序)
    - [http get post区别](#http-get-post区别)
- [机器学习](#机器学习)
    - [特征](#特征)
    - [AUC](#auc)
    - [SVM](#svm)
    - [lr](#lr)
    - [树](#树)
    - [LDA与PCA联系与区别](#lda与pca联系与区别)
    - [决策树，XGBoost，随机森林处理缺失值的方法？](#决策树xgboost随机森林处理缺失值的方法)
        - [决策树如何处理缺失值？（三个阶段：划分节点时--训练模型时--预测时）](#决策树如何处理缺失值三个阶段划分节点时--训练模型时--预测时)
        - [XGBoost里处理缺失值的方法](#xgboost里处理缺失值的方法)
        - [随机森林处理缺失值的方法](#随机森林处理缺失值的方法)
    - [优化方法的区别？](#优化方法的区别)
- [CUDA](#cuda)
    - [内存结构](#内存结构)
        - [CUDA里面的内存，问你各个内存快慢，存放在哪里，应用场景是什么](#cuda里面的内存问你各个内存快慢存放在哪里应用场景是什么)
        - [避免寄存器溢出](#避免寄存器溢出)
        - [问: 如何查看内核所用的寄存器数量或共享/常量内存大小？](#问-如何查看内核所用的寄存器数量或共享常量内存大小)

<!-- /TOC -->
# 网络
## 阐述TCP连接四次挥手
> CSDN/[TCP三次挥手和四次挥手](https://blog.csdn.net/qzcsu/article/details/72861891)
> 极客时间/[TCP](https://time.geekbang.org/column/article/8975)
- 请求->回应->回应回应
### TCP包头的格式
- 源端口号和目标端口号
- 包序号
- 包的确认序号
- 状态位：SYN 是发起一个连接，ACK 是回复，RST 是重新连接，FIN使结束连接
- 窗口大小


# 操作系统
## 进程间通讯
常见的通信方式：
1. 管道pipe：管道是一种半双工的通信方式，数据只能单向流动，而且只能在具有亲缘关系的进程间使用。进程的亲缘关系通常是指父子进程关系。
2. 命名管道FIFO：有名管道也是半双工的通信方式，但是它允许无亲缘关系进程间的通信。
4. 消息队列MessageQueue：消息队列是由消息的链表，存放在内核中并由消息队列标识符标识。消息队列克服了信号传递信息少、管道只能承载无格式字节流以及缓冲区大小受限等缺点。
5. 共享存储SharedMemory：共享内存就是映射一段能被其他进程所访问的内存，这段共享内存由一个进程创建，但多个进程都可以访问。共享内存是最快的 IPC 方式，它是针对其他进程间通信方式运行效率低而专门设计的。它往往与其他通信机制，如信号量，配合使用，来实现进程间的同步和通信。
6. 信号量Semaphore：信号量是一个计数器，可以用来控制多个进程对共享资源的访问。它常作为一种锁机制，防止某进程正在访问共享资源时，其他进程也访问该资源。因此，主要作为进程间以及同一进程内不同线程之间的同步手段。
7. 套接字Socket：套解口也是一种进程间通信机制，与其他通信机制不同的是，它可用于不同及其间的进程通信。
8. 信号 ( sinal ) ： 信号是一种比较复杂的通信方式，用于通知接收进程某个事件已经发生。
- 辅助命令
- ipcs命令用于报告共享内存、信号量和消息队列信息。
- ipcs -a：列出共享内存、信号量和消息队列信息。
- ipcs -l：列出系统限额。
- ipcs -u：列出当前使用情况。

## 进程和线程的区别
（1）进程是资源的分配和调度的一个独立单元，而线程是CPU调度的基本单元（根本区别：进程是操作系统资源分配的基本单位，而线程是任务调度和执行的基本单位）
（2）同一个进程中可以包括多个线程，并且线程共享整个进程的资源（寄存器、堆栈、上下文），一个进程至少包括一个线程。
（3）进程的创建调用fork或者vfork，而线程的创建调用pthread_create，进程结束后它拥有的所有线程都将销毁，而线程的结束不会影响同个进程中的其他线程的结束
（4）线程是轻两级的进程，它的创建和销毁所需要的时间比进程小很多，所有操作系统中的执行功能都是创建线程去完成的
（5）线程中执行时一般都要进行同步和互斥，因为他们共享同一进程的所有资源
（6）线程有自己的私有属性TCB，线程id，寄存器、硬件上下文，而进程也有自己的私有属性进程控制块PCB，这些私有属性是不被共享的，用来标示一个进程或一个线程的标志

## 如何查看一个进程打开了哪些文件？
lsof -P 18400 （按照进程ID查看）
lsof -d type (按照FD的类型查看）
lsof -i 4 (查看进程打开的网络连接，使用IPV4协议）
lsof -i :80 (查看进程打开的网络连接，端口号为80）
lsof -i @127.0.0.1 (查看进程打开的网络连接，IP为127.0.0.1）


## shell 
怎么实现对一个文件中的qq号出现次数统计？
A: 匹配腾讯QQ号：`^[1-9]*[1-9][0-9]*$`
Q: `grep -o '[1-9][0-9]*' QQ | sort | uniq -c| sort -r`  
Q: 如何打开一个100G的文件？
A: `split -l 100 abc.txt`
Q: 找出文本中包含某个词的行并且按照字典顺序排序？
A: `grep -nd xxx file` 

## tcp慢启动算法

## Mysql 比较熟悉是吧？说一下底层数据存储原理？
B+树，红黑树

## Python内置字典如何实现对value排序？

## http get post区别
post 的body可以被抓包，怎么防止？  改用HTTPs？
https怎么实现的？     拉闸，不会
arp协议全过程




# 机器学习
## 特征
特征为什么要归一化？归一化的三种方式？归一化后还要做什么？
特征选择的方法？

## AUC
ROC曲线下的面积，横坐标为false positive, 纵坐标为true positive

## SVM
- SVM为什么要从原始问题转变为对偶问题
1. 降低求解复杂度，原问题的最后求解是对w,b进行求解，其维数为训练样本的特征维数+1，对偶问题最后是对 \alpha 进行求解，其维数（个数）等于样本的个数，所以svm对于高维空间中较稀疏的样本表现较好
2. 方便核函数的引入

## lr
- 逻辑回归原理
- lr优缺点
- lr与SVM的区别和联系
```
联系：
1、LR和SVM都可以处理分类问题，且一般都用于处理线性二分类问题（在改进的情况下可以处理多分类问题）

2、两个方法都可以增加不同的正则化项，如l1、l2等等。所以在很多实验中，两种算法的结果是很接近的。

3、LR和SVM都可以用来做非线性分类，只要加核函数就好。

4、LR和SVM都是线性模型，当然这里我们不要考虑核函数

5、都属于判别模型

区别：

1、LR模型找到的那个超平面，是尽量让所有点都远离他，而SVM寻找的那个超平面，是只让最靠近中间分割线的那些点尽量远离，即只用到那些支持向量的样本。

2、从目标函数来看，区别在于逻辑回归采用的是logistical loss，SVM采用的是hinge loss，这两个损失函数的目的都是增加对分类影响较大的数据点的权重，减少与分类关系较小的数据点的权重。

3、逻辑回归相对来说模型更简单，好理解，特别是大规模线性分类时比较方便。而SVM的理解和优化相对来说复杂一些，SVM转化为对偶问题后,分类只需要计算与少数几个支持向量的距离,这个在进行复杂核函数计算时优势很明显,能够大大简化模型和计算。

4、SVM依赖penalty系数，实验中需要做CV

5、SVM本身是结构风险最小化模型，而LR是经验风险最小化模型

那怎么根据特征数量和样本量来选择SVM和LR模型呢？Andrew NG的课程中给出了以下建议：
如果Feature的数量很大，跟样本数量差不多，这时候选用LR或者是Linear Kernel的SVM
如果Feature的数量比较小，样本数量一般，不算大也不算小，选用SVM+Gaussian Kernel
如果Feature的数量比较小，而样本数量很多，需要手工添加一些feature变成第一种情况。(LR和不带核函数的SVM比较类似。)

```
逻辑回归SGD步长不对，收敛出现问题，该怎么解决？（减小学习率或者增大Batch Size）
逻辑回归模型里面有时一直收敛不到阈值以下的参数，该怎么做？
L1和L2的区别
手写逻辑回归目标函数，目标函数对w求导，手写。基础题。

## 树
树模型对归一化不敏感。
- **树模型的优势**？
- 树模型（非线性模型）和线性模型的区别？为什么会对离散、连续特征有统一的处理？
- 随机森林怎么才能学习出特征和特征之间的关系？
- GBDT、XGBoost、和RF的区别
```
GBDT和RF
1. 组成随机森林的树可以是分类树，也可以是回归树；而GBDT只由回归树组成，GBDT的会累加所有树的结果，而这种累加是无法通过分类完成的，因此GBDT的树都是CART回归树，而不是分类树（尽管GBDT调整后也可以用于分类但不代表GBDT的树为分类树）
2. 组成随机森林的树可以并行生成；而GBDT只能是串行生成 
3. 对于最终的输出结果而言，随机森林采用多数投票等；而GBDT则是将所有结果累加起来，或者加权累加起来 
4. 随机森林对异常值不敏感，GBDT对异常值非常敏感 
5. 随机森林对训练集一视同仁，GBDT是基于权值的弱分类器的集成 
6. 随机森林是通过减少模型方差提高性能，GBDT是通过减少模型偏差提高性能

GBDT与XGBoost
1. xgboost在代价函数里加入了正则项，用于控制模型的复杂度。正则项里包含了树的叶子节点个数、每个叶子节点上输出的score的L2模的平方和。从Bias-variance tradeoff角度来讲，正则项降低了模型的variance，使学习出来的模型更加简单，防止过拟合，这也是xgboost优于传统GBDT的一个特性
2. xgboost工具支持并行。boosting不是一种串行的结构吗?怎么并行的？注意xgboost的并行不是tree粒度的并行，xgboost也是一次迭代完才能进行下一次迭代的（第t次迭代的代价函数里包含了前面t-1次迭代的预测值）。xgboost的并行是在特征粒度上的。我们知道，决策树的学习最耗时的一个步骤就是对特征的值进行排序（因为要确定最佳分割点），xgboost在训练之前，预先对数据进行了排序，然后保存为block结构，后面的迭代中重复地使用这个结构，大大减小计算量。这个block结构也使得并行成为了可能，在进行节点的分裂时，需要计算每个特征的增益，最终选增益最大的那个特征去做分裂，那么各个特征的增益计算就可以开多线程进行。
AdaBoost 相对于 bagging 算法和 Random Forest 算法，AdaBoost 充分考虑的每个分类器的权重。
3. xgboost在代价函数里加入了正则项，用于控制模型的复杂度。正则项里包含了树的叶子节点个数、每个叶子节点上输出的score的L2模的平方和。从Bias-variance tradeoff角度来讲，正则项降低了模型的variance，使学习出来的模型更加简单，防止过拟合，这也是xgboost优于传统GBDT的一个特性

1. xgboost在目标函数中加入了正则化项，当正则化项为0时与传统的GDBT的目标函数相同2. xgboost在迭代优化的时候使用了目标函数的泰勒展开的二阶近似，paper中说能加快优化的过程！！xgboost可自定义目标函数，但是目标函数必须二阶可导也是因为这个。GDBT中只用了一阶导数。3. xgboost寻找最佳分割点时，考虑到传统贪心法效率比较低，实现了一种近似贪心法，除此之外还考虑了稀疏数据集、缺失值的处理，这能大大提升算法的效率。paper中提到在一个稀疏数据集中测试，发现速度提升了50倍。4. xgboost在算法实现时做了很多优化，大大提升了算法的效率，感叹陈天奇大牛深厚计算机基础！对训练的每个特征排序并且以块的的结构存储在内存中，方便后面迭代重复使用，减少计算量，不仅如此，在不同的特征属性上采用多线程并行方式寻找最佳分割点上述的优化导致每个样本的梯度信息在内存中不连续，直接累加有可能会导致cache-miss，所以xgboost先将样本的统计信息取到线程的内部buffer，然后再进行小批量的累加xgboost在实现时考虑了当训练数据很大、内存空间不够时，如何有效的利用磁盘空间？主要是利用了分块、预取、压缩、多线程协作的思想。

lightGBM

4.1 与XGboost对比

　　1、xgboost采用的是level-wise的分裂策略，而lightGBM采用了leaf-wise的策略，区别是xgboost对每一层所有节点做无差别分裂，可能有些节点的增益非常小，对结果影响不大，但是xgboost也进行了分裂，带来了额外的开销。 leaft-wise的做法是在当前所有叶子节点中选择分裂收益最大的节点进行分裂，如此递归进行，很明显leaf-wise这种做法容易过拟合，因为容易陷入比较高的深度中，因此需要对最大深度做限制，从而避免过拟合。

　　2、lightgbm使用了基于histogram的决策树算法，这一点不同与xgboost中的 exact 算法，histogram算法在内存和计算代价上都有不小优势。

　　（1）内存上优势：很明显，直方图算法的内存消耗为(#data*#features * 1Bytes)(因为对特征分桶后只需保存特征离散化之后的值)，而xgboost的exact算法内存消耗为：(2 * #data * #features* 4Bytes)，因为xgboost既要保存原始feature的值，也要保存这个值的顺序索引，这些值需要32位的浮点数来保存。

　　（2）计算上的优势，预排序算法在选择好分裂特征计算分裂收益时需要遍历所有样本的特征值，时间为(#data),而直方图算法只需要遍历桶就行了，时间为(#bin)

　　3、直方图做差加速

一个子节点的直方图可以通过父节点的直方图减去兄弟节点的直方图得到，从而加速计算。

　　4、lightgbm支持直接输入categorical 的feature

在对离散特征分裂时，每个取值都当作一个桶，分裂时的增益算的是”是否属于某个category“的gain。类似于one-hot编码。

　　5、实际上xgboost的近似直方图算法也类似于lightgbm这里的直方图算法，为什么xgboost的近似算法比lightgbm还是慢很多呢？

-. xgboost在每一层都动态构建直方图，因为xgboost的直方图算法不是针对某个特定的feature，而是所有feature共享一个直方图(每个样本的权重是二阶导),所以每一层都要重新构建直方图，而lightgbm中对每个特征都有一个直方图，所以构建一次直方图就够了。
```
- 树的深度、树的棵树是怎么调的？
- 信息增益、信息增益率、基尼系数三个公式

## LDA与PCA联系与区别
首先我们看看相同点：

1）两者均可以对数据进行降维。

2）两者在降维时均使用了矩阵特征分解的思想。

3）两者都假设数据符合高斯分布。

我们接着看看不同点：

1）LDA是有监督的降维方法，而PCA是无监督的降维方法

2）LDA降维最多降到类别数k-1的维数，而PCA没有这个限制。

3）LDA除了可以用于降维，还可以用于分类。

4）LDA选择分类性能最好的投影方向，而PCA选择样本点投影具有最大方差的方向。

## 决策树，XGBoost，随机森林处理缺失值的方法？
### 决策树如何处理缺失值？（三个阶段：划分节点时--训练模型时--预测时）
1. 在选择分裂属性的时候，训练样本存在缺失值，如何处理？假如你使用ID3算法，那么选择分类属性时，就要计算所有属性的熵增(信息增益，Gain)。假设10个样本，属性是a,b,c。在计算a属性熵时发现，第10个样本的a属性缺失，那么就把第10个样本去掉，前9个样本组成新的样本集，在新样本集上按正常方法计算a属性的熵增。然后结果乘0.9（新样本占raw样本的比例），就是a属性最终的熵。
2. 分类属性选择完成，对训练样本分类，发现属性缺失怎么办？比如该节点是根据a属性划分，但是待分类样本a属性缺失，怎么办呢？假设a属性离散，有1,2两种取值，那么就把该样本分配到两个子节点中去，但是权重由1变为相应离散值个数占样本的比例。然后计算错误率的时候，注意，不是每个样本都是权重为1，存在分数。
3. 训练完成，给测试集样本分类，有缺失值怎么办？这时候，就不能按比例分配了，因为你必须给该样本一个确定的label，而不是薛定谔的label。这时候根据投票来确定，或者填充缺失值。

### XGBoost里处理缺失值的方法
在xgboost里，在每个结点上都会将对应变量是缺失值的数据往左右分支各导流一次，然后计算两种导流方案对Objective的影响，最后认为对Objective降低更明显的方向（左或者右）就是缺失数据应该流向的方向，在预测时在这个结点上将同样变量有缺失值的数据都导向训练出来的方向。
例如，某个结点上的判断条件是 A>0 ，有些数据是A0，有些数据的A是缺失值。那么算法首先忽略带缺失值的数据，像正常情况下一样：

1. 将前两种数据分别计算并导流到左子树与右子树，
2. 然后将带缺失值的数据导向左子树，计算出这时候模型的Objective_L；
3. 接着将带缺失值的数据导向右子树，计算出这时候模型的Objective_R；
4. 最后比较Objective_L和Objective_R。
5. 假设Objective_L更小，那么在预测时所有变量A是缺失值的数据在这个结点上都会被导向左边，当作A<=0处理。

### 随机森林处理缺失值的方法
RandomForest包里有两种补全缺失值的方法：

方法一（na.roughfix）简单粗暴，对于训练集,同一个class下的数据，如果是分类变量缺失，用众数补上，如果是连续型变量缺失，用中位数补。

方法二（rfImpute）这个方法计算量大，至于比方法一好坏？不好判断。先用na.roughfix补上缺失值，然后构建森林并计算proximity matrix，再回头看缺失值，如果是分类变量，则用没有缺失的观测实例的proximity中的权重进行投票。如果是连续型变量，则用proximity矩阵进行加权平均的方法补缺失值。然后迭代4-6次，这个补缺失值的思想和KNN有些类似。

补充【proximity matrix】：Proximity 用来衡量两个样本之间的相似性。原理就是如果两个样本落在树的同一个叶子节点的次数越多，则这两个样本的相似度越高。当一棵树生成后，让数据集通过这棵树，落在同一个叶子节点的”样本对(xi,敏感词roximity 值 P(i,j)加 1。所有的树生成之后，利用树的数量来归一化proximity matrix。

## 优化方法的区别？
SGD、BGD等 区别 
- SGD
  - 每次读入一个数据，更新
  - 在线更新
  - 容易收敛到局部最低点和鞍点
- BGD
  - 所有数据更新
  - 凸函数能保证收敛，消耗内存大
- MBGD
  - 主流
- 为什么用MBGD？
  - 我们假设每个样本相对于大自然真实分布的标准差为σ，那么根据概率统计的知识，很容易推出n个样本的标准差为 $\sigma/\sqrt{n}$ （有疑问的同学快翻开概率统计的课本看一下推导过程）。从这里可以看出，我们使用样本来估计梯度的时候，1个样本带来σ的标准差，但是使用n个样本区估计梯度并不能让标准差线性降低（也就是并不能让误差降低为原来的1/n，即无法达到σ/n），而n个样本的计算量却是线性的（每个样本都要平等的跑一遍前向算法）。
  - > [训练神经网络时如何确定batch size？](https://zhuanlan.zhihu.com/p/27763696)
- 以上三种都需要调整学习率
- 动量法解决鞍点问题
- Adagrad/RMSprop/Adam
- 对于强大的二阶优化算法如共轭梯度法、L-BFGS来说，如果估计不好一阶导数，那么对二阶导数的估计会有更大的误差，这对于这些算法来说是致命的。
    - 对于二阶优化算法，减小batch换来的收敛速度提升远不如引入大量噪声导致的性能下降，因此在使用二阶优化算法时，往往要采用大batch哦。此时往往batch设置成几千甚至一两万才能发挥出最佳性能。

# CUDA
## 内存结构
### CUDA里面的内存，问你各个内存快慢，存放在哪里，应用场景是什么
> face2ai/[内存](https://www.face2ai.com/CUDA-F-4-1-%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B%E6%A6%82%E8%BF%B0/)   

- 寄存器(registers)
- Local memory
    - 高延迟、低带宽
    - 本地内存存储在每个SM的一级缓存，或者设备的二级缓存
- 共享内存（shared memory）
  - 共享内存是片上内存，跟主存相比，速度要快很多，也即是延迟低，带宽高。其类似于一级缓存，但是可以被编程。
  - 延迟低，带宽高
  - 共享内存的时候一定要注意，不要因为过度使用共享内存，而导致SM上活跃的线程束减少，也就是说，一个线程块使用的共享内存过多，导致更过的线程块没办法被SM启动，这样影响活跃的线程束数量
  - SM中的一级缓存，和共享内存共享一个64k的片上内存（不知道现在的设备有没有提高），他们通过静态划分，划分彼此的容量，运行时可以通过下面语句进行设置：
- 全局内存（global memory）
  - 全局内存访问是对齐，也就是一次要读取指定大小（32，64，128）整数倍字节的内存
- 常量内存（constant memory）
  - 设备内存
  - 常量内存的读取机制是：一次读取会广播给所有线程束内的线程。
- 纹理内存（texture memory）
  - 纹理内存驻留在设备内存中，在每个SM的只读缓存中缓存，纹理内存是通过指定的缓存访问的全局内存，只读缓存包括硬件滤波的支持，它可以将浮点插入作为读取过程中的一部分来执行，纹理内存是对二维空间局部性的优化。总的来说纹理内存设计目的应该是为了GPU本职工作显示设计的，但是对于某些特定的程序可能效果更好，比如需要滤波的程序，可以直接通过硬件完成。

### 避免寄存器溢出
添加__lauch_bounds__关键字
```c++
__global__ void
__lauch_bounds__(maxThreadaPerBlock,minBlocksPerMultiprocessor)
kernel(...) {
    /* kernel code */
```

### 问: 如何查看内核所用的寄存器数量或共享/常量内存大小？ 
在 nvcc 命令行中添加「--ptxas-options=-v」选项即可。在编译过程中，此信息将输出至控制台。